[
["index.html", "Kvantitative metoder for de finansielle uddannelser.", " Kvantitative metoder for de finansielle uddannelser. Thomas Petersen 2018-07-28 "],
["sandsynligheder.html", "Kapitel 1 Sandsynligheder 1.1 Betingede sandsynligheder 1.2 Uafhængighed", " Kapitel 1 Sandsynligheder .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; } Vi vil her se på sandsynligheder. Hvis vi forestiller os, man har på en cafe har spurgt 800 besøgende, om de drikker the, kaffe eller begge dele, og har fået følgende svar. Kaffe The Både kaffe og the 600 400 200 Vi kan opstille resultaterne i et Venn-diagram som vist på figuren. Vi kan udføre et stokastisk eksperiment og tilfældigt udtage en person og undersøge, hvor stor sandsynligheden er for at vedkommende drikker kaffe. Vi skriver P for probability dvs. sandsynlighed. Sandsynligheden for en person drikker kaffe kan opskrives som: \\[\\small P(Kaffe)=\\frac{Antal\\ kaffe-drikkere}{Antal\\ adspurgte}=\\frac{600}{800}=0.75=75\\%\\] På samme måde kan man finde sandsynligheden for at en person drikker the: \\[\\small P(The)=\\frac{Antal\\ the-drikkere}{Antal\\ adspurgte}=\\frac{400}{800}=0.5=50\\%\\] 1.1 Betingede sandsynligheder Vi kan også se på en mindre gruppe af de adspurgte, hvis fx. man kun vil se på kaffedrikkerne kunne man ønske at undersøge, hvor stor en andel af kaffedrikkerne der både drikker the og kaffe. Vi siger at vi betinger med en hændelse, hvis vi ser på en sådan delmængde af de adspurgte. Betingede sandsynligheder kan formuleres på flere måder fx: Givet at man drikker kaffe hvad er da sandsynligheden for at man ligeledes drikker the? Hvis man drikker kaffe hvad er da sandsynligheden for at man ligeledes drikker the? Hvad er da sandsynligheden for, at man drikker the, når man drikker kaffe? Hvad er andelen af kaffedrikkere, der drikker the? Vi siger vi betinger med hændelsen A, man drikker kaffe, og ser således kun på gruppen af kaffedrikkere. Hvad er så sandsynligheden for at man også drikker the hændelsen B? Vi skal altså bestemme sandsynligheden for B givet A, med symboler skriver vi det som \\(\\small P(B\\mid A)\\). Vi kan udregne dette som \\[\\small P(B\\mid A)=\\frac{P(B\\cap A)}{P(A)}\\] Det betyder vi kan udregne hvad er andelen af kaffedrikkere, der drikker the, ved formlen: \\[\\small P(B\\mid A)=P(kaffe\\ og\\ the\\mid kaffe)=\\frac{P(kaffe\\ og\\ the\\cap kaffe)}{P(kaffe)}\\] \\[\\small \\frac{\\frac{200}{800}}{\\frac{600}{800}}=\\frac{200}{600}=\\frac{1}{3}\\approx 33\\%\\] 1.1.1 Race og dødsdom eksempel I et kendt studie fra 1991 af Radelet and Pierce, om Florida, har man indsamlet data i retssager hvor der var mulighed for dødsstraf. Man har blandt andet indsamlet data om den tiltaltes etnicitet, offerets etnicitet samt udfaldet af retssagen dvs. om den tiltalte blev idømt dødstraf eller ikke. Studiets formål var at afgøre om der ved domstolene er en bias, således at amerikanere af afrikansk afstamning oftere idømmmes dødsstraf end hvide. Race tiltalt Dødsdom Ikke dødsdom Total Hvid 53 430 483 Afrikansk amerikaner 15 176 191 Total 68 606 674 Sandsynligheden for at blive dødsdømt, når man er tiltalt kan udregnes til: \\[\\small P(dø\\ dsdom)=\\frac{dø\\ dsdø\\ mte}{alle\\ tiltalte}=\\frac{68}{674}=0.1009\\] Sandsynligheden for at blive dødsdømt, når man er hvid og tiltalt er en betinget sandsynlighed, denne kan udregnes til: \\[\\small P(dø\\ dsdom\\mid hvid)=\\frac{P(dø\\ dsdom \\cap hvid)}{P(hvide\\ tiltalte)}=\\frac{53}{483}=0.1097\\] Sandsynligheden for at blive dødsdømt, hvis man er afrikansk-amerikaner og tiltalt er en betinget sandsynlighed, denne kan udregnes til: \\[\\small P(dø\\ dsdom\\mid sort)=\\frac{P(dø\\ dsdom\\cap sort)}{P(sorte\\ tiltalte)}=\\frac{15}{191}=0.0785\\] Dette tyder ikke på at der er racemæssig forskel på andelen af dødsdømte. 1.2 Uafhængighed Vi kan sige at 2 hændelser A og B er uafhængige hvis sandsynligheden for at den ene hændelse indtræffer ikke påvirkes af om den anden hændelse indtræffer eller ej. Dette kan vi udtrykke vha. betingede sandsynligheder. \\[\\small P(A\\mid B)=P(A)\\] Her står sandsynligheden for A er den samme ligegyldigt om hændelsen B indtræffer eller ej. \\[\\small P(B\\mid A)=P(B)\\] Her står sandsynligheden for B er den samme ligegyldigt om hændelsen A indtræffer eller ej. Vi kan omskrive begge ligninger til nedenstående resultat. \\[\\small P(A\\mid B)=P(A)\\Leftrightarrow \\frac{P(A\\cap B)}{P(B)}=P(A)\\Leftrightarrow P(A\\cap B)=P(A)\\cdot P(B)\\] Så hændelserne A og B er uafhængige hvis fælleshændelsen \\(\\small P(A\\cap B)\\) er lig med produktet af hændelserne \\(\\small P(A) \\cdot P(B)\\) Er hændelserne drikke kaffe og the uafhængige? Vi finder sandsynligheden for fælleshændelsen: \\[\\small P(Kaffe \\cap The)=\\frac{200}{800}=0.25\\] Er sandsynligheden for fælleshændelsen lig med produktet af sandsynlighederne? \\[\\small P(Kaffe)\\cdot P(The)=\\frac{600}{800}\\cdot \\frac{400}{800}=\\frac{3}{4}\\cdot \\frac{1}{2}=\\frac{3}{8}=0.375\\] Hændelserne er altså ikke uafhængige for 0.25 er ikke 0.375. Vi ser på om hændelserne hvid tiltalt og dødsdom er afhængige. Vi finder sandsynligheden for fælleshændelsen: \\[\\small P(Dø\\ dsdom \\cap Hvid)=\\frac{53}{674}=0.08\\] Er sandsynligheden for fælleshændelsen lig med produktet af sandsynlighederne? \\[\\small P(Dø\\ dsdom)\\cdot P(Hvid)=\\frac{68}{674}\\cdot \\frac{483}{674}=0.10 \\cdot 0.72=0.072\\] Sandsynlighederne 0.08 og 0.072 er tæt på hinanden, udtaler vi os om en population ville vi nok ikke kunne afvise at hændelserne er uafhængige. Vi vil i afsnittede om Chi i anden tests se på hvorledes man tester uafhængighed. Spørgsmål dødsdom Vi inddeler nu skemaet ovenfor, med en variabel, der angiver offerets race. Race offer Race tiltalt Dødsdom Ikke dødsdom Total Hvid Hvid 53 414 467 Hvid Afrikansk amerikaner 11 37 48 Afrikansk amerikaner Hvid 0 16 16 Afrikansk amerikaner Afrikansk amerikaner 4 139 143 Total 68 606 674 1. Hvad er sandsynligheden for at blive dødsdømt, hvis man er hvid tiltalt for at have dræbt en hvid? 2. Hvad er sandsynligheden for at blive dødsdømt, givet man er sort tiltalt for at have dræbt en hvid? 3. Hvad er sandsynligheden for at blive dødsdømt, givet man er hvid tiltalt for at have dræbt en sort? 4. Hvad er sandsynligheden for at blive dødsdømt, når man er sort tiltalt for at have dræbt en sort? Svar dødsdom 1. Sandsynligheden for at blive dødsdømt, hvis man er hvid tiltalt for at have dræbt en hvid kan udregnes til: \\[\\small P(Dø\\ dsdø\\ mt \\mid hvid\\ tiltalt\\ og\\ hvidt\\ offer)=\\frac{53}{467}=0.1135\\] 2. Sandsynligheden for at blive dødsdømt, givet man er sort tiltalt for at have dræbt en hvid kan udregnes til: \\[\\small P(Dø\\ dsdø\\ mt \\mid sort\\ tiltalt\\ og\\ hvidt\\ offer)=\\frac{11}{48}=0.2292\\] 3. Sandsynligheden for at blive dødsdømt, givet man er hvid tiltalt for at have dræbt en sort kan udregnes til: \\[\\small P(Dø\\ dsdø\\ mt \\mid hvid\\ tiltalt\\ og\\ sort\\ offer)=\\frac{0}{16}=0\\] 4. Sandsynligheden for at blive dødsdømt, når man er sort tiltalt for at have dræbt en sort kan udregnes til \\[\\small P(Dø\\ dsdø\\ mt \\mid sort\\ tiltalt\\ og\\ sort\\ offer)=\\frac{4}{143}=0.0280\\] Vi ser nu at der synes at være større sandsynlighed for dødsdom for sorte end for hvide, denne effekt kommer først frem når vi kontrollerer for offer race. Man kalder dette for Simpsons paradoks. "],
["chi-i-anden-tests.html", "Kapitel 2 Chi i anden tests 2.1 Goodness of fit test 2.2 Forudsætning 2.3 Chi i anden test 2.4 Chi i anden test 2 2.5 Selvtest", " Kapitel 2 Chi i anden tests 2.1 Goodness of fit test .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; } Goodnees of fit testen er en udvidelse af z-testet for en andel. Med test af andele kan man fx. undersøge om andelen af mænd er 60% og kvinder 40% i en population, vi tester altså fordelingen for en kvalitativ variabel med 2 mulige udfald. Med et goodness of fit test kan vi teste kvalitative variable med 2 eller flere mulige udfald, man kan fx. undersøge om fordelingen af boligform i en stikprøve kan antages at svare til fordelingen på regionsplan: 50% ejer, 20% andel og 30% leje. Vi tester vha. Chi i anden fordelingen. Teststørrelsen vi finder, udtrykker forskellen mellem det vi observerer i stikprøven og det vi tester under nulhypotesen. Antag man simpelt tilfældigt har udtaget en stikprøve på 150 boliger, der indeholder 60 ejer- 40 andels- og 50 lejeboliger. Hvis vi vil undersøge undersøge om fordelingen af boligform i stikprøven, kan antages at følge regionsfordelingen som er 50% ejer, 20% andel og 30% leje, opstiller vi følgende hypoteser: \\[H_0:p_{ejer}=0.5\\ p_{andel}=0.2\\ p_{leje}=0.3\\]\\[H_1:Fordelingen\\ af\\ boliger\\ fø\\ lger\\ ikke\\ samme\\ fordeling\\ som\\ i\\ regionen\\] Teststørrelsen findes som: \\[\\chi^2=\\sum^k_{j=1}\\frac{(O-E)^2}{E}\\] Hvor O er observerede værdier og E er forventede værdier det stammer fra expected på engelsk, k angiver antallet af mulige udfald for den kvalitative variabel. For at beregne teststørrelsen bestemmer vi E, antallet af ejer, leje og andel vi ville forvente i en stikprøve på netop 150 boliger, der perfekt repræsenterede regionen. ejer: \\(0.5\\cdot150=75\\) andel: \\(0.2\\cdot150=30\\) leje: \\(0.3\\cdot150=45\\) Vi kan nu udregne teststørrelsen som: \\[\\chi^2=\\frac{(60-75)^2}{75}+\\frac{(40-30)^2}{30}+\\frac{(50-45)^2}{45}=3+3\\frac{1}{3}+\\frac{5}{9}=6.8889\\] Vi sammenligner med chi i anden fordelingen med k-1=3-1=2 frihedsgrader \\(\\chi^2_2\\), den kritiske værdi bliver 5.9915 hvilket giver p-værdien 0.0319, illustreret ved den gule hale i figuren nedenfor. Da teststørrelsen 6.89 er større end den kritiske værdi 5.99, får vi en p-værdi der er mindre end 5% signifikanssandsynligheden. Vi forkaster nulhypotesen og konkluderer, fordelingen af boligtyper i populationen, er ikke identiske med fordelingen i regionen. I Freestat tastes input i de hvide felter, hvilket resulterer i følgende resultat: 2.2 Forudsætning En forudsætning for at goodness of fit testet er tilstrækkeligt præcist, er at de forventede værdier E er tilstrækkeligt store. Der er mange forskellige tolkninger, af størrelsen af E cellerne. Nogle nævner celleværdier skal være større end 3 andre 5, det bør under alle omstændigheder nævnes om forudsætningen synes opfyldt. Hvis de forventede værdier er meget små, kan man sammenlægge kategorier, der vil så være et tradeoff med detaljegraden af analysen. Hvis man sammenlægger bør man gøre dette, så det analytisk giver mening. I eksemplet med boligtyper, havde vi forventede værdier E på hhv. 75, 30 og 45, her var forudsætningen altså opfyldt. Spørgsmål datasæt karakterer Undervisningsministeriet har et ønske om at karaktererne på landsplan bør normaliseres omkring 7, hvor der er følgende procentvise vægt på hver karakter Karakter Ønsket fordeling 02 10% 4 25% 7 30% 10 25% 12 10% Der er intet krav til andelen af studerende der består, således drejer fordelingen sig udelukkende om bestået-karakterer. Hent datasættet statkarakterer for stikprøven for statistikstuderende , betragt kun de beståede studerende, kan populationen antages at følge de generelle retningslinjer? Svar datasæt karakterer Vi starter med at se på de beståede 37 studerende, optæl fx. vha. =countif eller =tælhvis i excel for at bestemme antallet af studerende med de respektive karakterer. Karakter Ønsket fordeling Observeret antal Observeret Frekvens 02 10% 9 0.2432 4 25% 6 0.1622 7 30% 5 0.1351 10 25% 12 0.3243 12 10% 5 0.1351 Vi kan nu bestemme den forventede karakterfordeling hvis karaktererne følger den ønskede fordeling. Karakter Ønsket fordeling Forventet antal Chi i anden bidrag 02 10% 3.7 7.5919 4 25% 9.25 1.1419 7 30% 11.1 3.3523 10 25% 9.25 0.8176 12 10% 3.7 0.4568 Bemærk forventede værdier er mindre end 5 men større end 3, der kan være problemer med præcisionen. Hvis man ønsker at sammenlægge kategorier giver det ikke mening at lægge 02 og 12 sammen, men gerne 02 og 4 eller 10 og 12. Summen af chi i anden bidrag giver teststørrelsen, dvs: 7.5919+1.1419+3.3523+0.8176=13.3604 Hvilket fører til p-værdien 0.0096 illustreret ved den gule hale herunder, da p-værdien er mindre end 5% signifikansniveauet forkaster vi nulhypotesen, og konkluderer at statistikkarakterer på Finansøkonom ikke følger den ønskede fordeling. Vi kan ud fra chi i anden bidragene se hvilke karakterer der giver de største afvigelser. Store bidrag betyder store afvigelser mellem det observede og ønskede. Det største bidrag 7.5919 stammer fra 02 karakteren, her er den observerede karakter 9, mens den forventede værdi er 3.7. Der er altså flere studerende, end forventet der får 02. Bemærk for at vi kan udtale os om populationen finansøkonomer, fordres at stikprøven er repræsentativ for finansøkonomer. Stikprøven er ikke udtaget simpelt tilfældigt, da der er tale om 2 bestemte klasser, det kan derfor diskuteres om stikprøven er afspejler populationen korrekt. Freestat output bliver: 2.3 Chi i anden test .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; } 2.4 Chi i anden test 2 .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; } Vi kan analysere kvalitative variable med 2 mulige udfald vha. test af 2 andele. Chi i anden testet er en udvidelse af test af 2 andele. Med chi i anden testen kan man sammenligne kvalitative variable med 2 eller flere mulige udfald. Vi kan benytte chi i anden testet til at undersøge om der er en sammenhæng mellem 2 inddelingskriterier som fx. køn og bestået/ikke bestået, køn og karakter, aldersgruppe og karakter. Antag et forsikringsselskab har indsamlet data for kunders skadesanmeldelser fordelt på øst og vest for Storebælt. Forsikringsselskabet ønsker at undersøge om der er forskel i andelen af kunder der anmelder skader i Øst- og Vestdanmark. Følgende data er angivet Observeret Ingen skader anmeldt 1 eller flere skader Total Østdanmark 300 300 600 Vestdanmark 250 150 400 Total 550 450 1000 Vi kan teste om der er forskel på om der er forskel på andelen af anmeldte skader i Øst- og Vestdanmark vha. chi i anden testet. Vi har følgende hypoteser. \\[H_0: Der\\ er\\ uafhæ\\ \\ ngighed\\ mellem\\ ræ\\ kke-\\ og\\ sø\\ jlekriterierne\\]\\[H_1: Der\\ er\\ afhæ\\ \\ ngighed\\ mellem\\ ræ\\ kke-\\ og\\ sø\\ jlekriterierne\\] Eller mere præcist i dette tilfælde: \\[H_0: Der\\ er\\ uafhæ\\ \\ ngighed\\ mellem\\ landsdel\\ og\\ skadesanmeldelse\\]\\[H_1: Der\\ er\\ afhæ\\ \\ ngighed\\ mellem\\ landsdel\\ og\\ skadesanmeldelse\\] Hvis nulhypotesen forkastes påvirker landsdelen kunder kommer fra altså andelen af anmeldte skader. 2.4.1 Uafhængighed Definitionen af uafhængighed mellem 2 hændelser A og B er at sandsynligheden for fælleshændelsen er lig med produktet af sandsynlighederne for enkelthændelserne som formel skriver vi: \\[P(A\\cap B)=P(A)\\cdot P(B)\\] Vores hændelse A kan fx. være kunden stammer fra Østdanmark, og hændelse B at kunden har ikke anmeldt skader. Vi får da følgende ligning: \\[P(Ø\\ \\ stdanmark\\cap 0\\ skader)=P(Ø\\ \\ stdanmark)\\cdot P(0\\ skader)\\] Vi kan omskrive dette til: \\[P(Ø\\ \\ stdanmark\\cap0\\ skader)=P(Ø\\ \\ stdanmark)\\cdot P(0\\ skader)\\Leftrightarrow \\frac{300}{1000}=\\frac{600}{1000}\\cdot \\frac{550}{1000} \\Leftrightarrow \\]\\[1000\\cdot\\frac{300}{1000}=1000\\cdot \\frac{600\\cdot550}{1000\\cdot1000} \\Leftrightarrow 300= \\frac{600\\cdot550}{1000}\\] Her er venstresiden i ligningen jo den observerede celleværdi. Hvis der er uafhængighed under nulhypotesen, vil vi forvente at den observerede værdi, er lig med venstresiden, som vi kalder den forventede værdi. Hvis der er perfekt uafhængighed mellem landsdel og skadesanmeldelse, ville vi altså i hver celle forvente værdien: \\[\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}\\] Vi får derfor følgende matrice. Forventet Ingen skader anmeldt 1 eller flere skader Total Østdanmark \\(\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}=\\frac{600\\cdot 550}{1000}=330\\) \\(\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}=\\frac{600\\cdot 450}{1000}=270\\) 600 Vestdanmark \\(\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}=\\frac{400\\cdot 550}{1000}=220\\) \\(\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}=\\frac{400\\cdot 450}{1000}=180\\) 400 Total 550 450 1000 Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet: \\[\\frac{(O-E)^2}{E}\\] Chi celle bidrag Ingen skader anmeldt 1 eller flere skader Total Østdanmark \\(\\frac{(300-330)^2}{330}=2.7272727\\) \\(\\frac{(300-270)^2}{270}=3.3333333\\) Vestdanmark \\(\\frac{(250-220)^2}{220}=4.0909091\\) \\(\\frac{(150-180)^2}{180}=5\\) Total 15.15 Teststørrelsen bliver 15.15, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader for chi i anden fordelingen er antallet af rækkeinddelingskriterier Østdanmark og Vestdanmark minus 1, gange antallet af søjleinddelingskriterier 0 skader og flere end 0 skader minus 1, dvs. \\[(r-1)\\cdot(s-1)=(2-1)\\cdot(2-1)=1\\cdot1=1\\] Vi får p-værdien 9.910^{-5}, hvilket er klart mindre end signifikansniveauet på 5%, arealet er så lille vi ikke kan se det på figuren nedenfor. Vi forkaster altså nulhypotesen og konstaterer der er afhængighed mellem landsdel og anmeldte skader. Landsdelen som kunden stammer fra, påvirker altså antallet af anmeldte skader. Vi kan nu se om der er chi i anden bidrag, der er meget store og dermed bidrager stæ til konklusionen om afhængighed. Der er ikke en voldsom forskel i størrelserne på chi i anden bidragene, men når vi ser på observeret mod forventet, ser vi at 150 anmelder skader, det var forventet at 180 personer fra Vestdanmark anmelder skader. Denne tendens er modsat for Østdanmark. Vestdanmark anmelder altså færre skader end Østdanmark. Ligesom for goodness of fit testet, skal de forventede værdier have en vis størrelse for at vore konklusioner er præcise. Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler. Freestat output bliver 2.4.2 Anmeldte skader fordelt på regioner og antal skader Vi antager nu der foreligger mere specifikke data for undersøgelsen omkring geografisk placering og skadesanmeldelse.Vi har finere inddeling på region og antal skader. Observeret 0 skader 1 skade 2 eller flere skader Total Hovedstaden 150 125 50 325 Sjælland 150 100 25 275 Syddanmark 75 30 10 115 Midtjylland 75 40 10 125 Nordjylland 100 45 15 160 Total 550 340 110 1000 Vi kan teste om der er forskel på om der er forskel på andelen af anmeldte skader i Øst- og Vestdanmark vha. chi i anden testet. Vi har følgende hypoteser. \\[H_0: Der\\ er\\ uafhæ\\ \\ ngighed\\ mellem\\ region\\ og\\ antal skader\\]\\[H_1: Der\\ er\\ afhæ\\ \\ ngighed\\ mellem\\ region\\ og\\ antal skader\\] Hvis nulhypotesen forkastes påvirker regionen kunder kommer fra altså antallet af anmeldte skader. Vi beregner de forventede værdier efter den sædvanlige formel: \\[\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}\\] Hvilket giver følgende matrix Forventet 0 skader 1 skade 2 eller flere skader Total Hovedstaden 178.75 110.5 35.75 325 Sjælland 151.25 93.5 30.25 275 Syddanmark 63.25 39.1 12.65 115 Midtjylland 68.75 42.5 13.75 125 Nordjylland 88 54.4 17.6 160 Total 550 340 110 1000 Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet: \\[\\frac{(O-E)^2}{E}\\] Chi celle bidrag 0 skader 1 skade 2 eller flere skader Total Hovedstaden 4.6241259 1.9027149 5.6800699 12.2069107 Sjælland 0.0103306 0.4518717 0.911157 1.3733593 Syddanmark 2.1828063 2.1179028 0.5551383 4.8558475 Midtjylland 0.5681818 0.1470588 1.0227273 1.7379679 Nordjylland 1.6363636 1.6242647 0.3840909 3.6447193 Total 9.0218082 6.2438129 8.5531835 23.8188046 Teststørrelsen bliver 23.82, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver \\[(r-1)\\cdot(s-1)=(5-1)\\cdot(3-1)=4\\cdot 2=8\\] Vi får p-værdien 0.002458, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem region og antal anmeldte skader. Regionen som kunden stammer fra, påvirker altså antallet af anmeldte skader. Vi kan se, der er chi i anden bidrag, der er store for region København, disse bidrager kraftigt til konklusionen om afhængighed. Københavnerne anmelder flere skader end forventet, dermed er der færre københavnere end forventet, der ikke anmelder skader. Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler. Freestat output bliver Spørgsmål Titanic I 1912 forliste Titanic, vi har i filen oplysninger om passagererne. Har man har større chance for at overleve, hvis man er velhavende? Vi har ikke oplysninger om passagerernes formuer, men vi kan bruge oplysningerne om billetterne som en proxy for velstand. Variablen pclass angiver hvilken billet den pågældende passager havde, 1. klasse er dyrest. Variablen survived fortæller om en passager overlevede 1 eller døde 0. Data er i filen Titanic. Svar Titanic Vi sorterer passagerer efter billet og om de har overlevet. Observeret Døde Overlevede Total 1. Klasse 123 200 323 2. Klasse 158 119 277 3. Klasse 528 181 709 Total 809 500 1309 Vi kan teste om der er billettype betyder noget for overlevelse. Vi får følgende hypoteser: \\[H_0: Der\\ er\\ uafhæ\\ \\ ngighed\\ mellem\\ passagerklasse\\ og\\ overlevelse\\]\\[H_1: Der\\ er\\ afhæ\\ \\ ngighed\\ mellem\\ passagerklasse\\ og\\ overlevelse\\] Hvis nulhypotesen forkastes betyder passagerklasse noget for noget for overlevelsen Vi beregner de forventede værdier: \\[\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}\\] Hvilket giver følgende matrix Forventet Døde Overlevede Total 1. Klasse 199.62 123.38 323 2. Klasse 171.19 105.81 277 3. Klasse 438.18 270.82 709 Total 809 500 1309 Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet: \\[\\frac{(O-E)^2}{E}\\] Chi celle bidrag Døde Overlevede Total 1. Klasse 29.4111 47.5871 76.9982 2. Klasse 1.0169 1.6453 2.6622 3. Klasse 18.4105 29.7882 48.1987 Total 48.8385 79.0207 127.8592 Teststørrelsen bliver 127.86, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver \\[(r-1)\\cdot(s-1)=(3-1)\\cdot(2-1)=2\\cdot 1=2\\] Vi får p-værdien 0, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem passagerklasse og overlevelse. Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler. Vi kan se at 200 1. klasses passagerer overlevede mod forventet 123.38 under nulhypotesen, hvilket giver et meget stort chi i anden bidrag. Omvendt overlevede kun 181 3. klasses passagerer mod 270.82 forventet under nulhypotesen. Der var altså væstentlig større chance for overlevelse hvis man er velhavende. Spørgsmål bankansatte Vi ser på data for bankansatte i filen Bankdata filen. Er der sammenhæng mellem jobfunktion og køn? Svar bankansatte Vi sorterer personalet efter jobfunktion og køn. Observeret Kvinde Mand Total Administration 206 157 363 Sikkerhedspersonale 0 27 27 Ledelse 10 74 84 Total 216 258 474 Vi kan teste om der er billettype betyder noget for overlevelse. Vi får følgende hypoteser: \\[H_0: Der\\ er\\ uafhæ\\ \\ ngighed\\ mellem\\ jobfunktion\\ og\\ kø\\ n\\]\\[H_1: Der\\ er\\ afhæ\\ \\ ngighed\\ mellem\\ jobfunktion\\ og\\ kø\\ n\\] Hvis nulhypotesen forkastes har køn betydning for jobfunktion. Vi beregner de forventede værdier: \\[\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}\\] Hvilket giver følgende matrix Forventet Kvinde Mand Total Administration 165.42 197.58 363 Sikkerhedspersonale 12.3 14.7 27 Ledelse 38.28 45.72 84 Total 216 258 474 Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet: \\[\\frac{(O-E)^2}{E}\\] Chi celle bidrag Kvinde Mand Total Administration 9.9561 8.3354 18.2915 Sikkerhedspersonale 12.3038 10.3009 22.6047 Ledelse 20.8909 17.4901 38.381 Total 43.1508 36.1264 79.2772 Teststørrelsen bliver 79.28, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver \\[(r-1)\\cdot(s-1)=(3-1)\\cdot(2-1)=2\\cdot 1=2\\] Vi får en meeget lille p-værdi afrundet til 0, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem jobfunktion og køn. Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler. Udfra tabellerne ses at mænd er underrepræsenteret i administrationen og overrepræsenteret i sikkerhedspersonale og ledelse. Spørgsmål bankansatte Vi ser fortsat på data for bankansatte i filen Bankdata filen. Er der sammenhæng mellem jobfunktion og minoritet? Minoritet er ikke-hvide. Svar bankansatte Vi sorterer personalet efter jobfunktion og køn. Observeret Ikke-minoritet minoritet Total Administration 276 87 363 Sikkerhedspersonale 14 13 27 Ledelse 80 4 84 Total 370 104 474 Vi kan teste om minoritet betyder noget for jobfunktion. Vi får følgende hypoteser: \\[H_0: Der\\ er\\ uafhæ\\ \\ ngighed\\ mellem\\ jobfunktion\\ og\\ minoritet\\]\\[H_1: Der\\ er\\ afhæ\\ \\ ngighed\\ mellem\\ jobfunktion\\ og\\ minoritet\\] Hvis nulhypotesen forkastes betyder det at tilhører man en minoritet har dette betydning for jobfunktionen. Vi beregner de forventede værdier: \\[\\frac{ræ\\ \\ kkesum\\cdot sø\\ jlesum}{totalsum}\\] Hvilket giver følgende matrix Forventet Ikke-minoritet Minoritet Total Administration 283.35 79.65 363 Sikkerhedspersonale 21.08 5.92 27 Ledelse 65.57 18.43 84 Total 370 104 474 Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet: \\[\\frac{(O-E)^2}{E}\\] Chi celle bidrag Ikke-minoritet minoritet Total Administration 0.1909 0.6791 0.87 Sikkerhedspersonale 2.3756 8.4518 10.8274 Ledelse 3.1758 11.2985 14.4743 Total 5.7423 20.4294 26.1717 Teststørrelsen bliver 26.17, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver \\[(r-1)\\cdot(s-1)=(3-1)\\cdot(2-1)=2\\cdot 1=2\\] Vi får en lille p-værdi på 210^{-6}, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem jobfunktion og om man tilhører en minoritet. Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler. Udfra tabellerne ses at minoriteter er overrepræsenteret blandt administration og sikkerhedspersonale og underrepræsenteret i ledelsen. 2.5 Selvtest Selvtest Chi i anden med videoløsninger "],
["anova.html", "Kapitel 3 ANOVA 3.1 Selvtest", " Kapitel 3 ANOVA .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; } ANOVA er en metode til at sammenligne middelværdierne for mere end to kvantitative variable. Skal man sammenligne to middelværdier med varianshomogenitet, benytter man pooled t-test, er der mere end 2 middelværdier benyttes ANOVA F-test . Forudsætningerne for at benytte testen er at populationerne er normalfordelte og har samme varians. ANOVA er en forkortelse af analysis of variances, man tester om middelværdierne er ens vha. varianserne. Vi undersøger om k populationer har samme middelværdi, hypoteserne bliver: \\[H_0:\\mu_1=\\mu_2=...=\\mu_k\\]\\[H_1:Ikke\\ alle\\ middelvæ\\ rdier\\ er\\ ens.\\] Den totale variation SST kan opdeles i SSW og SSA hvor, SSW er variationen indenfor de k grupper, SSA er variationen mellem grupperne. Hvis variationen indenfor grupperne SSW er lille i forhold til variationen mellem grupperne SSA, er middelværdierne ikke ens. Herunder er et eksempel, hvor populationerne er dagsafkast for aktier, variationen indenfor grupperne SSW er lille i forhold til variationen mellem grupperne SSA, derfor er middelværdierne signifikant forskellige. Herunder er en figur med dagsafkast for aktier, hvor variationen indenfor grupperne SSW er stor i forhold til variationen mellem grupperne SSA, derfor er middelværdierne ikke signifikant forskellige. Herunder er et eksempel hvor forudsætningen om varianshomogenitet ikke er opfyldt, de 3 aktier har forskelligt variation. Et forsikringsselskab har udviklet 4 forskellige layouts til information om skadesdækning. Brugerne udsættes vilkårligt for et af de 4 layouts, selskabet registrerer tiderne for besøgene på hjemmesiderne for at afgøre hvilket design, der er optimalt mht. brugervenlighed og overskuelighed. .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; } Hent datasættet Hjemmesidedesigns besøgstider i millisekunder, der viser de 359 observede besøgstider på de 4 hjemmesider. Forsikringsselskabet ønsker at undersøge om der er forskel på besøgstiderne, vi opstiller hypoteserne: \\[H_0:\\mu_{Design 1}=\\mu_{Design 2}=\\mu_{Design 3}=\\mu_{Design 4}\\]\\[H_1:Ikke\\ alle\\ middelvæ\\ rdier\\ er\\ ens\\ for\\ de\\ 4\\ designs.\\] Freestat output Vi får en F-teststørrelse på 6.0429, der resulterer i en p-værdi på 0.0005, hvilket er under signifikansniveauet på 0.05. Vi kan forkaster altså nulhypotesen om ens middelværdier. Freestat output Vi skal tjekke forudsætningen om varianshomogenitet \\[H_0:\\sigma_{Design 1}=\\sigma_{Design 2}=\\sigma_{Design 3}=\\sigma_{Design 4}\\]\\[H_1:Ikke\\ alle\\ varianser\\ er\\ ens\\ for\\ de\\ 4\\ designs.\\] Vi får en teststørrelse på 1.4742741. Chi i anden testet giver os en p-værdi på 0.6882205, hvilket er større end signifikanssandsynligheden på 0.05, vi kan ikke afvise nulhypotesen. Varianserne er ens, så forudsætningen er opfyldt. Freestat output af Bartlett test for varianshomogenitet Normalitet Herunder er 4 normalfraktildiagrammer, for de 4 designs, vi kan godt antage, stikprøverne stammer fra normalfordelte populationer. Tukey Kramer Vi kan undersøge hvilke designs der har de største afvigelser ved at se på forskellene mellem stikprøvegennemsnittene, der er størst forskel mellem besøgstiderne for design 1 og design 4. Vi kan grafisk sammenligne middelværdierne i boxplots, her ser vi ligeledes forskellen er størst mellem design 1 og design 4. Middelværdierne er markeret med orange prikker. Spørgsmål 3 banker afkast Hent datasættet 3 Danske Banker Ugeafkast i procent , i dette datasæt er de seneste 239 ugers afkast i procent for hhv. Danske Bank, Jyske Bank og Sydbank. Er der signifikant forskel på afkastene på de 3 bankaktier? Svar 3 banker afkast Vi opstiller hypoteserne for test af om middelværdierne er identiske: \\[H_0:\\mu_{Danske Bank}=\\mu_{Jyske Bank}=\\mu_{Sydbank}\\]\\[H_1:Ikke\\ alle\\ middelvæ\\ rdier\\ er\\ ens\\ for\\ de\\ 3\\ banker\\] Vi får variationen i grupperne SSW til 296772869957.892 og variationen mellem grupperne SSA til 15155248763.2056. Dette giver en F-teststørrelse på 6.0429 der resulterer i p-værdi på 0.0005. Vi kan altså ikke forkaste altså nulhypotesen om ens middelværdier. Vi kan da også se at de absolutte forskelle mellem stikprøvegennemsnittene er relativt små: Forskelle mellem Banker Absolutte forskelle Danske Bank - Jyske Bank 0.12 Danske Bank - Sydbank 0.05 Jyske Bank - Sydbank 0.17 Vi skal tjekke forudsætningen om varianshomogenitet \\[H_0:\\sigma_{Danske Bank}=\\sigma_{Jyske Bank}=\\sigma_{Sydbank}\\]\\[H_1:Ikke\\ alle\\ varianser\\ er\\ ens\\ for\\ de\\ 3\\ banker.\\] Vi får en teststørrelse på 8.5786057. Chi i anden testet giver os en p-værdi på 0.0137145, hvilket er mindre end signifikanssandsynligheden på 0.05, vi afviser nulhypotesen. Varianserne er ikke ens, så forudsætningen er ikke opfyldt. Vi kan således have problemer med kvaliteten af analysen. Normalitet Vi kan grafisk sammenligne middelværdierne for ugeafkastet for de 3 banker i boxplots , her ser vi der ikke er stor forskel på middelværdierne. Middelværdierne er markeret med orange prikker. Spørgsmål IMDB Hent IMDB data, der viser data for 759 film simpelt tilfældigt udtrukket af en database med 759 film. Vi ønsker at se om, der er forskel på vurderingen af de forskellige genrer action, komedie, drama, documentar, romance og short, undersøg dette vha. ANOVA test Svar IMDB Vi opstiller hypoteserne: \\[H_0:\\mu_{action}=\\mu_{komedie}=\\mu_{drama}=\\mu_{documentar}=\\mu_{romance}=\\mu_{short}\\]\\[H_1:Ikke\\ alle\\ middelvæ\\ rdier\\ er\\ ens\\ for\\ de\\ 5\\ genrer.\\] Vi får en F-teststørrelse på 10.786, der resulterer i en meget lille p-værdi på 0, hvilket er klart under signifikansniveauet på 0.05. Vi kan forkaster altså nulhypotesen om ens middelværdier. Vi skal tjekke forudsætningen om varianshomogenitet \\[H_0:\\sigma_{action}=\\sigma_{komedie}=\\sigma_{drama}=\\sigma_{documentar}=\\sigma_{romance}=\\sigma_{short}\\]\\[H_1:Ikke\\ alle\\ standardafvigelser\\ er\\ ens\\ for\\ de\\ 5\\ genrer.\\] Vi får en teststørrelse på 7.1306596. Chi i anden testet giver os en p-værdi på 0.2111029. Normalitet Herunder er 5 normalfraktildiagrammer, for de 5 genrer, dokumentar og short genrerne ser ikke normalfordelte ud. Hvilket kan give problemer med kvaliteten i vor analyse. Vi kan ud fra boxplots se at dokumentarfilm rates højt i modsætning til actionfilm. Vi kan i tabellen herunder se hvor de største forskelle er mellem genrerne. Forskelle gennemsnit genrer Absolutte forskelle Action - dokumentar 1.5465517 Action - drama 0.9324561 Action - komedie 0.3148402 Action - romance 0.6735294 Action - short 0.788806 Dokumentar - drama 0.6140956 Dokumentar - komedie 1.2317115 Dokumentar - romance 0.8730223 Dokumentar - short 0.7577458 Drama - komedie 0.617616 Drama - romance 0.2589267 Drama - short 0.1436502 Komedie - romance 0.3586892 Komedie - short 0.4739658 Romance - short 0.1152766 3.1 Selvtest Selvtest Anova analyse med videoløsninger "],
["kvantitative-metoder.html", "Kapitel 4 Kvantitative metoder", " Kapitel 4 Kvantitative metoder .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; } Gennemgangen af tidsrækkeanalyse bygger meget på praktisk anvendelighed (dvs. vi vil gerne kunne forudsige kursudviklingen), vi vil springe let hen over teorien der kan være tung og er meget omfattende. Nedenstående links giver dog en indføring i den teoretiske del, som vi her ikke berører. http://ucanalytics.com/blogs/arima-models-manufacturing-case-study-example-part-3/ http://ucanalytics.com/blogs/step-by-step-graphic-guide-to-forecasting-through-arima-modeling-in-r-manufacturing-case-study-example/ Her er en gennemgang af forskellige typer af tidsrækker man kan opleve. https://people.duke.edu/~rnau/411arim.htm#arima010 Video om ARIMA https://youtu.be/Aw77aMLj9uM "],
["arima000.html", "Kapitel 5 ARIMA(0,0,0)", " Kapitel 5 ARIMA(0,0,0) Nedenfor har vi aktiekurser for 50 dage for en fiktiv aktie, vi vil nu undersøge om disse kan bruges til at forudsige noget om fremtidige aktiekurser. For at gøre dette, skal man enten importere Excelfilen, eller copy paste data fra rammen nedenfor. Data nedenfor kan kopieres direkte ind i R. Navngiv data ARIMA1 ved at skrive følgende tekst foran det du kopierer. ARIMA1 &lt;- structure(c(21.64, 19.62, 14.7, 20.52, 19.94, 20.1, 19.46, 20.76, 20.64, 15.66, 18.76, 22.24, 22.94, 16.56, 18.44, 17.98, 20.6, 19.86, 18.28, 18.1, 18.54, 20.86, 19.4, 23.86, 18.44, 20.48, 21.92, 19.42, 18.96, 22.52, 21.28, 19.64, 21.38, 18.26, 16.48, 17.92, 20.72, 20.14, 18.58, 21.34, 21.12, 21.96, 19.74, 20.02, 16.3, 23.12, 21.26, 18.52, 24.58, 21.26), .Dim = c(50L, 1L), .Dimnames = list( NULL, &quot;Dagskurs&quot;), .Tsp = c(1, 50, 1), class = &quot;ts&quot;) Vi kan nu plotte vore data i R. plot.ts(ARIMA1, xlab=&#39;Tid&#39;, ylab = &#39;Kursdata&#39;) Det er svært at se nogen tydelig udvikling i kursen. Vi benytter auto.arima til at undersøge om der er en systematik i tidsserien, for at bruge denne funktion skal vi hente og loade pakken forecast med hhv. install.packages(“forecast”) kun første gang og require(“forecast”) eller library(“forecast”) auto.arima(ARIMA1) ## Series: ARIMA1 ## ARIMA(0,0,0) with non-zero mean ## ## Coefficients: ## mean ## 19.8964 ## s.e. 0.2872 ## ## sigma^2 estimated as 4.209: log likelihood=-106.37 ## AIC=216.74 AICc=217 BIC=220.57 Funktionen auto.arima i R finder automatisk den ARIMA model der passer bedst på observationerne. Output ARIMA(0,0,0) with non-zero mean, fortæller os at data er ligesom hvid støj. Den bedste forudsigelse af aktieprisen vi kan komme med er gennemsnittet af alle kurserne. Vi kan altså ikke forudsige prisen vha. vore fine værktøjer. Akaike Information Criterion (AIC) , og Bayesian Information Criterion (BIC) benyttes til at vælge ARIMA modellen med mindst AIC og BIC værdier. auto.arima finder den bedste model automatisk. Her er ligningen for aktiekursen, den bedste forudsigelse af den fremtidige kurs er den gennemsnitlige kurs der tidligere er observeret. \\[\\hat{Y_t}=19.90\\] "],
["arima100-eller-ar1-autoregression.html", "Kapitel 6 ARIMA(1,0,0) eller AR(1) autoregression", " Kapitel 6 ARIMA(1,0,0) eller AR(1) autoregression Vi ser nu på 50 dagskurser for en anden aktie, kopier data ind i R og navngiv med ARIMA2: structure(c(97.957, 73.334, 83.723, 92.322, 106.694, 94.278, 118.855, 107.169, 116.21, 124.179, 105.945, 100.359, 131.513, 103.029, 104.339, 103.513, 108.638, 97.032, 100.426, 91.356, 110.501, 116.041, 106.145, 96.257, 101.983, 124.107, 112.892, 121.101, 103.067, 98.862, 94.009, 115.093, 103.553, 92.895, 103.087, 89.622, 91.413, 116.587, 119.88, 111.579, 100.377, 108.997, 104.367, 82.48, 79.99, 85.062, 102.597, 98.046, 101.043, 109.051), .Dim = c(50L, 1L), .Dimnames = list(NULL, &quot;Dagskurs&quot;), .Tsp = c(1, 50, 1), class = &quot;ts&quot;) ts.plot(ARIMA2) auto.arima(ARIMA2) ## Series: ARIMA2 ## ARIMA(1,0,0) with non-zero mean ## ## Coefficients: ## ar1 mean ## 0.3664 103.2372 ## s.e. 0.1301 2.4492 ## ## sigma^2 estimated as 128.3: log likelihood=-191.36 ## AIC=388.73 AICc=389.25 BIC=394.46 Her afslører auto.arima 1. ordens autoregression dvs. Modellen kan skrives som. \\[\\hat{Y_t}=c + \\phi Y_{t-1}\\] Vi forestiller os eksemplet hvor den sande middelværdi for tidsrækken er \\(\\mu=100\\) og \\(\\phi=0.5\\) for en ARIMA(1,0,0) model. Så kan vi beregne \\(c=(1-\\phi)\\cdot \\mu=(1-0.5)\\cdot 100=50\\) er middelværdien estimeret ved den gennemsnitlige kurs. Ligningen for modellen kan så skrives som: \\[\\hat{Y_t}=c + \\phi Y_{t-1} \\Leftrightarrow \\hat{Y_t}=50 + 0.5 Y_{t-1}\\] \\(\\phi\\) fortæller, hvis kursen dagen før var 80 gennemsnitskursen er 100, vil kursen imorgen ifølge modellen være forudsagt som \\(50+0.5\\cdot 80=90\\) dagen efter vil den så være \\(50+0.5\\cdot 90=95\\). De forudsagte værdier konvergerer (nærmer sig) mod \\(\\mu\\). AR i ARIMA, står for autoregression, selv-regression mod middelværdien, i eksemplet så vi hvordan værdien nærmer sig 100, hvis vi forudsiger flere dages kurser kan vi se dette. \\(\\phi\\) må kun antage værdier mellem og ikke lig med -1 og 1, hvilket betyder den er stationær, altså nærmer sig den sande middelværdi \\(\\mu\\). Hvad vil der ske hvis \\(\\mu=100\\) og \\(\\phi=-0.5\\) for en ARIMA(1,0,0) model (husk \\(c=(1-\\phi)\\cdot\\mu\\) når man skal bestemme modellen)? Vi kan nu i R forudsige aktiekursen 12 perioder frem med predict: predict(auto.arima(ARIMA2), n.ahead = 12)$pred ## Time Series: ## Start = 51 ## End = 62 ## Frequency = 1 ## [1] 105.3673 104.0177 103.5232 103.3420 103.2756 103.2513 103.2424 ## [8] 103.2391 103.2379 103.2375 103.2373 103.2373 "],
["arima010-eller-i1-random-walk-with-a-drift.html", "Kapitel 7 ARIMA(0,1,0) eller I(1) Random Walk with a drift", " Kapitel 7 ARIMA(0,1,0) eller I(1) Random Walk with a drift Hvis en serie er ikke-stationær, er den simpleste model en random walk: \\[\\hat{Y_t}-Y_{t-1}=\\mu\\Leftrightarrow \\hat{Y_t}=\\mu-Y_{t-1}\\] Dette betyder at Y stiger konstant med \\(\\mu\\) i hver periode. Drift betyder at tidsrækken stiger konstant. Kald den næste vektor for ARIMA3: structure(c(100, 110.695, 116.16, 123.983, 124.182, 118.432, 114.157, 116.126, 126.584, 139.104, 149.709, 166.794, 172.85, 168.264, 184.061, 188.304, 196.156, 203.239, 217.565, 226.016, 236.986, 250.127, 254.33, 255.305, 280.172, 295.641, 323.152, 337.009, 344.1, 371.613, 383.138, 390.722, 390.121, 392.329, 408.905, 423.546, 411.232, 436.033, 441.104, 433.005, 436.042, 455.257, 455.92, 473.371, 475.472, 490.525, 492.407, 500.438, 506.987, 504.54, 495.746), .Dim = c(51L, 1L), .Dimnames = list( NULL, &quot;Dagskurs&quot;), .Tsp = c(1, 51, 1), class = &quot;ts&quot;) ts.plot(ARIMA3) auto.arima(ARIMA3) ## Series: ARIMA3 ## ARIMA(0,1,0) with drift ## ## Coefficients: ## drift ## 7.9149 ## s.e. 1.2790 ## ## sigma^2 estimated as 83.46: log likelihood=-181.05 ## AIC=366.1 AICc=366.36 BIC=369.93 Modellen ovenfor kan skrives som: \\[\\hat{Y_t}-Y_{t-1}=\\mu\\Leftrightarrow \\hat{Y_t}-Y_{t-1}=7.9\\] Vi indsætter drift i stedet for \\(\\mu\\), tolningen er at modellen forudsiger at aktiekursen stiger med 7.9 fra periode til periode. Forstiller man sig en ARIMA(0,1,0) med drift 10 og en kurs på tidspunkt t-1 på 120, vil vi forudsige en kurs på 130 ved tid t og 140 ved tid t+1 osv. Hvis vi har en ren random walk model uden drift dvs. med \\(\\mu=0\\) ARIMA(0,1,0) for en aktiekurs , forventer vi at kursen til tid t vil være den samme som til tid t-1. Denne kan skrives som: \\[\\hat{Y_t}-Y_{t-1}=0\\] "],
["arima001-eller-ma1-moving-average.html", "Kapitel 8 ARIMA(0,0,1) eller MA(1) Moving average", " Kapitel 8 ARIMA(0,0,1) eller MA(1) Moving average Vi kan i stedet for at bruge tidligere aktiekurser til at forudsige aktiekursen i stedet benytte tidligere målefejl residualer til at forudsige kursen. Modellen kan skrives som: \\[\\hat{Y_t}=\\mu+\\theta_1 e_{t-1}\\] Hvis vi forestiller os \\(\\mu=50\\) \\(\\theta_1=0.5\\) kursen til tid t-1 var 120 forudsigelsen til tid t-1 var 100, så målefejlen residualen til tid t-1 er \\(e_{t-1}\\) er faktisk kurs minus forudsagt kurs altså 120-100=20. Nu kan vi forudsige kursen til tid t som: \\[\\hat{Y_t}=\\mu+\\theta_1 e_{t-1}\\Leftrightarrow \\hat{Y_t}=50+0.5\\cdot20=60\\] Data der kan indlæses i R, benævn data som ARIMA4: structure(c(104.035, 84.696, 66.622, 75.078, 90.512, 80.213, 95.646, 120.728, 107.473, 98.007, 105.692, 91.47, 81.564, 90.325, 112.94, 128.034, 118.113, 108.337, 92.803, 85.981, 91.068, 90.237, 94.939, 87.966, 93.857, 110.179, 99.252, 84.86, 80.571, 74.44, 107.43, 112.259, 97.252, 96.04, 93.651, 113.215, 116.992, 100.672, 93.411, 104.566, 115.626, 93.047, 91.644, 120.28, 109.674, 95.901, 102.858, 105.829, 99.581, 112.855), .Dim = c(50L, 1L), .Dimnames = list( NULL, &quot;Dagskurs&quot;), .Tsp = c(1, 50, 1), class = &quot;ts&quot;) ts.plot(ARIMA4) auto.arima(ARIMA4) ## Series: ARIMA4 ## ARIMA(0,0,1) with non-zero mean ## ## Coefficients: ## ma1 mean ## 0.9053 99.0176 ## s.e. 0.0664 2.5588 ## ## sigma^2 estimated as 95.68: log likelihood=-184.81 ## AIC=375.62 AICc=376.14 BIC=381.35 Vi kan nu forudsige aktiekursen 12 perioder frem med predict: predict(auto.arima(ARIMA4), n.ahead = 12)$pred ## Time Series: ## Start = 51 ## End = 62 ## Frequency = 1 ## [1] 113.64960 99.01756 99.01756 99.01756 99.01756 99.01756 99.01756 ## [8] 99.01756 99.01756 99.01756 99.01756 99.01756 Hvorfor svarer den forudsagte værdi til mean i en ren ARIMA(0,0,1) eller MA(1) model? (Vink hvad er definitionen på en residual) "],
["plots-med-forskellige-modeller.html", "Kapitel 9 Plots med forskellige modeller", " Kapitel 9 Plots med forskellige modeller ## Series: ap1 ## ARIMA(0,1,1) ## ## Coefficients: ## ma1 ## -0.7061 ## s.e. 0.1256 ## ## sigma^2 estimated as 105: log likelihood=-187.13 ## AIC=378.26 AICc=378.52 BIC=382.09 Kursen svinger omkring middelværdien. ## Series: ap2 ## ARIMA(1,1,0) ## ## Coefficients: ## ar1 ## 0.4037 ## s.e. 0.1292 ## ## sigma^2 estimated as 98.93: log likelihood=-185.39 ## AIC=374.78 AICc=375.04 BIC=378.61 ## Series: ap3 ## ARIMA(1,0,1) with non-zero mean ## ## Coefficients: ## ar1 ma1 mean ## -0.3027 0.8446 99.2526 ## s.e. 0.0990 0.0600 0.9596 ## ## sigma^2 estimated as 93.45: log likelihood=-736.4 ## AIC=1480.8 AICc=1481 BIC=1493.99 Vi kan også grafisk vise hvordan kursen vil udvikle sig med 80% og 95% konfidensbælter. forecast(auto.arima(ap3)) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 201 103.47198 91.08316 115.8608 84.52491 122.4190 ## 202 97.97536 83.88432 112.0664 76.42498 119.5257 ## 203 99.63927 85.40243 113.8761 77.86590 121.4126 ## 204 99.13558 84.88545 113.3857 77.34188 120.9293 ## 205 99.28805 85.03670 113.5394 77.49250 121.0836 ## 206 99.24190 84.99044 113.4934 77.44617 121.0376 ## 207 99.25587 85.00440 113.5073 77.46013 121.0516 ## 208 99.25164 85.00017 113.5031 77.45589 121.0474 ## 209 99.25292 85.00145 113.5044 77.45717 121.0487 ## 210 99.25253 85.00106 113.5040 77.45679 121.0483 plot(forecast(auto.arima(ap3))) #ARIMA af højere orden Arima modeller kan afhænge af flere tidligere perioder, fx kan ligningen for ARIMA(2,0,0) eller AR(2), opskrives som: \\[\\hat{Y_t}=c + \\phi Y_{t-1}+ \\phi_2 Y_{t-2}\\] Modellen afhænger altså af 2 tidligere perioder (lags) og ikke en. Man betegner dette som en model med lag 2. Arima modeller kan indeholde flere forskellige elementer med lag som fx. ARIMA(0,2,1). "],
["arima-og-ssonalitet.html", "Kapitel 10 ARIMA og sæsonalitet 10.1 Traktorer 10.2 Detail debet card forbrug på Island (millioner ISK).", " Kapitel 10 ARIMA og sæsonalitet Hvis fx. en aktie handles lavere om fredagen kan ARIMA modellerne korrigere for dette ved sæsonkorrektion. I sæsonkorrigerede modeller vises dette som en ekstra vektor med 3 tal for hhv. sæsonkorrigeret AR eller SAR, sæsonkorrigeret I eller SI og sæsonkorrigeret MA eller SMA. En model som ARIMA(1,0,0)(1,0,0) har altså udover AR også en sæsonkomponent. #ARIMA eksempler 10.1 Traktorer Hent følgende data for traktor salg, med følgende kommandoer i R. data = read.csv(&#39;http://ucanalytics.com/blogs/wp-content/uploads/2015/06/Tractor-Sales.csv&#39;) data = ts(data[,2],start = c(2003,1),frequency = 12) Vi ser salget er voksende over tid, der er ligeledes en sæsonkomponent. plot(data, xlab=&#39;Years&#39;, ylab = &#39;Tractor Sales&#39;) Differens tranformer data for at generere stationære data mht. middel (fjern trend) plot(diff(data),ylab=&#39;Differenced Tractor Sales&#39;) log transformer data for at sikre stationaritet mht. varians. plot(log10(data),ylab=&#39;Log (Tractor Sales)&#39;) Eventuel Differens og log transformation af data for at sikre stationaritet både mht. middel og varians. plot(diff(log10(data)),ylab=&#39;Differenced Log (Tractor Sales)&#39;) Find bedste model med auto.arima, når der er stationaritet. Akaike Information Criterion (AIC) , og Bayesian Information Criterion (BIC), vælg ARIMA modellen med mindst AIC and BIC værdier. auto.arima finder den bedste model automatisk. require(forecast) ARIMAfit = auto.arima(log10(data), approximation=FALSE,trace=FALSE) ARIMAfit ## Series: log10(data) ## ARIMA(0,1,1)(0,1,1)[12] ## ## Coefficients: ## ma1 sma1 ## -0.4047 -0.5529 ## s.e. 0.0885 0.0734 ## ## sigma^2 estimated as 0.0002571: log likelihood=354.4 ## AIC=-702.79 AICc=-702.6 BIC=-694.17 Nu kan vi forudsige kommende traktor salg med modellen par(mfrow = c(1,1)) pred = predict(ARIMAfit, n.ahead = 36) salg &lt;- 10^pred$pred salg ## Jan Feb Mar Apr May Jun Jul ## 2015 567.7645 566.4765 670.8226 758.9138 855.9482 817.2827 938.7239 ## 2016 625.2464 623.8280 738.7384 835.7481 942.6065 900.0265 1033.7626 ## 2017 688.5479 686.9859 813.5300 920.3613 1038.0383 991.1474 1138.4233 ## Aug Sep Oct Nov Dec ## 2015 934.5120 703.5005 626.9879 571.9988 668.5363 ## 2016 1029.1243 774.7246 690.4657 629.9094 736.2206 ## 2017 1133.3154 853.1596 760.3701 693.6830 810.7573 plot(data,type=&#39;l&#39;,xlim=c(2003,2018),ylim=c(1,1600),xlab = &#39;Year&#39;,ylab = &#39;Tractor Salg&#39;) lines(10^(pred$pred),col=&#39;blue&#39;) lines(10^(pred$pred+2*pred$se),col=&#39;orange&#39;) lines(10^(pred$pred-2*pred$se),col=&#39;orange&#39;) 10.2 Detail debet card forbrug på Island (millioner ISK). #Hent fpp pakken og load den plot(debitcards) dldebitcards &lt;- diff(log10(debitcards)) plot(dldebitcards,ylab=&quot;Differenced Log (debitcards)&quot;) require(forecast) ARIMAfit = auto.arima(log10(debitcards), approximation=FALSE,trace=FALSE) ARIMAfit ## Series: log10(debitcards) ## ARIMA(2,1,0)(0,1,1)[12] ## ## Coefficients: ## ar1 ar2 sma1 ## -0.7167 -0.4372 -0.8352 ## s.e. 0.0761 0.0763 0.1085 ## ## sigma^2 estimated as 0.0004402: log likelihood=343.95 ## AIC=-679.9 AICc=-679.61 BIC=-668.05 Nu kan vi forudsige kommende debetkort omsætning med modellen par(mfrow = c(1,1)) pred = predict(ARIMAfit, n.ahead = 36) plot(debitcards,type=&#39;l&#39;,xlim=c(2000,2016),ylim=c(1,40000),xlab = &#39;Year&#39;,ylab = &#39;Debetcard usage&#39;) lines(10^(pred$pred),col=&#39;blue&#39;) lines(10^(pred$pred+2*pred$se),col=&#39;orange&#39;) lines(10^(pred$pred-2*pred$se),col=&#39;orange&#39;) Forudsagt brug af debetkort bliver: 10^(pred$pred) ## Jan Feb Mar Apr May Jun Jul ## 2013 19717.77 19162.87 20436.29 20506.84 23262.14 23545.62 24292.86 ## 2014 20701.39 20352.57 21886.85 21721.53 24745.18 25091.09 25806.49 ## 2015 22017.60 21649.95 23281.85 23104.56 26321.98 26689.74 27450.29 ## Aug Sep Oct Nov Dec ## 2013 25544.16 22267.47 22543.80 22081.63 29090.93 ## 2014 27175.65 23697.15 23970.40 23490.36 30947.83 ## 2015 28907.08 25206.87 25497.43 24986.92 32919.46 "],
["forecast-aktiekurser.html", "Kapitel 11 Forecast Aktiekurser", " Kapitel 11 Forecast Aktiekurser Man kan hente online aktiekurser med quantmod pakken installer denne med install.packages og library kommandoerne. Vi henter nedenfor Google lukkekurs til dato. getSymbols(&quot;GOOG&quot;,from = &quot;2017-01-01&quot;, to = Sys.Date(),getSymbols.warning4.0=FALSE) ## [1] &quot;GOOG&quot; plot(GOOG[,6],main = &quot;Google adj. close&quot;) agoog &lt;- auto.arima(GOOG[,6]) agoog ## Series: GOOG[, 6] ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## 0.0799 1.1423 ## s.e. 0.0539 0.7210 ## ## sigma^2 estimated as 176.6: log likelihood=-1577.28 ## AIC=3160.56 AICc=3160.62 BIC=3172.49 fagoog &lt;- forecast(agoog) fagoog ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 396 1237.150 1220.121 1254.179 1211.106 1263.194 ## 397 1238.292 1213.228 1263.356 1199.960 1276.624 ## 398 1239.434 1208.347 1270.521 1191.891 1286.978 ## 399 1240.577 1204.457 1276.696 1185.337 1295.817 ## 400 1241.719 1201.187 1282.251 1179.731 1303.707 ## 401 1242.861 1198.353 1287.370 1174.791 1310.931 ## 402 1244.004 1195.845 1292.162 1170.352 1317.655 ## 403 1245.146 1193.595 1296.696 1166.306 1323.985 ## 404 1246.288 1191.556 1301.021 1162.582 1329.994 ## 405 1247.430 1189.691 1305.170 1159.125 1335.735 plot(fagoog,main = &quot;Google adj. close&quot;) require(&quot;quantmod&quot;) getSymbols(&quot;GS&quot;,from = &quot;2017-01-01&quot;, to = Sys.Date(),getSymbols.warning4.0=FALSE) ## [1] &quot;GS&quot; plot(GS[,6],main = &quot;Goldman Sachs adj. close&quot;) ags &lt;- auto.arima(GS[,6]) ags ## Series: GS[, 6] ## ARIMA(0,1,0) ## ## sigma^2 estimated as 10.09: log likelihood=-1014.44 ## AIC=2030.88 AICc=2030.89 BIC=2034.86 fags &lt;- forecast(ags) fags ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 396 237.64 233.5691 241.7109 231.4141 243.8659 ## 397 237.64 231.8829 243.3971 228.8352 246.4448 ## 398 237.64 230.5890 244.6910 226.8564 248.4236 ## 399 237.64 229.4982 245.7818 225.1882 250.0918 ## 400 237.64 228.5372 246.7428 223.7184 251.5616 ## 401 237.64 227.6683 247.6117 222.3897 252.8903 ## 402 237.64 226.8694 248.4106 221.1678 254.1122 ## 403 237.64 226.1257 249.1543 220.0304 255.2496 ## 404 237.64 225.4273 249.8527 218.9622 256.3178 ## 405 237.64 224.7666 250.5134 217.9519 257.3281 plot(fags,main = &quot;Goldman Sachs adj. close&quot;) require(&quot;quantmod&quot;) getSymbols(&quot;DANSKE.CO&quot;,from = &quot;2017-01-01&quot;, to = Sys.Date(),getSymbols.warning4.0=FALSE) ## [1] &quot;DANSKE.CO&quot; plot(DANSKE.CO[,6],main = &quot;Danske Bank adj. close&quot;) addb &lt;- auto.arima(DANSKE.CO[,6]) addb ## Series: DANSKE.CO[, 6] ## ARIMA(0,2,1) ## ## Coefficients: ## ma1 ## -0.9899 ## s.e. 0.0072 ## ## sigma^2 estimated as 6.312: log likelihood=-909.64 ## AIC=1823.28 AICc=1823.31 BIC=1831.21 faddb &lt;- forecast(addb) faddb ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 393 187.4959 184.2762 190.7156 182.5718 192.4201 ## 394 187.1919 182.6155 191.7683 180.1929 194.1908 ## 395 186.8878 181.2546 192.5210 178.2726 195.5030 ## 396 186.5837 180.0464 193.1210 176.5858 196.5817 ## 397 186.2797 178.9341 193.6252 175.0457 197.5136 ## 398 185.9756 177.8888 194.0623 173.6080 198.3432 ## 399 185.6715 176.8934 194.4496 172.2465 199.0965 ## 400 185.3674 175.9367 194.7981 170.9444 199.7905 ## 401 185.0634 175.0112 195.1155 169.6899 200.4368 ## 402 184.7593 174.1113 195.4073 168.4745 201.0441 plot(faddb,main = &quot;Danske Bank adj. close&quot;) "]
]
